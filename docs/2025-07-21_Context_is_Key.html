<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Context is Key discusses how providing too much or unfocused context to large language models (LLMs) can be counterproductive, leading to issues like context poisoning, distraction, confusion, and clash.">
  <title>gaurang.dev | Context is Key</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <div class="container">
    <header class="header">
      <a href="https://gaurang.dev"><h1>gaurang.dev</h1></a>
      
      <ul>     
        <li><a href="00_about.html">About</a></li>
        <li><a href="00_posts.html">Posts</a></li>
        <li><a href="00_contact.html">Contact</a></li>
      </ul>
      
    </header>

    <h2>Context is Key</h2>
    <p style="color: #a8a8a8">
      2025-07-21
    </p>
    <div class="content">



<h1>Context is Key</h1>
<p>While it may seem that providing more context would lead to better results, the opposite can often be the case. A large and unfocused context can be detrimental to the outcome. Providing models with large context might not work as expected:</p>
<table>
  <tbody>
    <tr>
      <td><b color="darkred">Context Poisoning</b><br>When LLM hallucinates &amp; generates factually incorrect information that gets incorporated into the context leading to a cascade of errors.</td>
      <td><b color="darkred">Context Confusion</b><br>This is where unnecessary and irrelevant information in the context affects the response.</td>
    </tr>
    <tr>
      <td><b color="darkred">Context Distraction</b><br>Here the large volume of information overwhelms the models training causing it to lose focus on the users primary query.</td>
      <td><b color="darkred">Context Clash</b><br>When different parts of the context disagree with each other, leading to an incoherent response.</td>
    </tr>
  </tbody>
</table>
<p>How can we provide LLMs with relevant context without falling into these traps? "<b>Retrieval-Augmented Generation</b>" (RAG) is a powerful method that involves selectively adding relevant information to the context at the time of the query.</p>
<table>
  <tbody>
    <tr>
      <td><b color="darkgreen">Context Sandbox</b><br>Isolate context in dedicated threads preventing it from interfering with other parts of the models processing.</td>
      <td><b color="darkgreen">Context Summary</b><br>Provide a condensed version of the context to the model for processing.</td>
    </tr>
    <tr>
      <td><b color="darkgreen">Context Priming</b><br>Removing unneeded or redundant information from the context before it is fed to the LLM.</td>
      <td><b color="darkgreen">Context Offloading</b><br>Store information outside the immediate context of the LLM and using tools to access it only when needed.</td>
    </tr>
    <tr>
      <td colspan="2"><b color="darkgreen">Tool Loadout</b><br>Select only the most relevant tools for the task at hand. This concept is similar to how players in games like Counter-Strike select their "loadout" before a match begins. Just as a player chooses the most relevant weapons, grenades, and armor for the upcoming round based on their strategy, map and the opposing team, we should select only the most relevant tools for the task at hand.</td>
    </tr>
  </tbody>
</table>

<p>
   <a style="float:right;" href="00_posts.html">all posts =&gt;</a>
</p>

    </div>

    <footer class="footer">
      <p>&copy; 2025
 Gaurang Sinha. All rights reserved.</p>
      <p>built using <a href="https://github.com/gaurangsinha/m4ke">m4ke</a></p>
    </footer>
  </div>
</body>
</html>



